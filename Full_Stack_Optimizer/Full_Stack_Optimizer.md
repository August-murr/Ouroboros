# What is a Full-Stack Optimizer?

Modern AI systems consist of many layers: training pipelines, model architectures, inference kernels, data preprocessing scripts, evaluation harnesses, prompts, tool definitions, and orchestration logic. In a typical organization, different teams manually engineer each component—ML engineers design training loops, systems engineers optimize kernels, prompt engineers craft instructions, data engineers build pipelines. Currently, only one part of this stack scales with compute: the neural network weights. Everything else requires human iteration and expertise.

A **full-stack optimizer** is an autonomous agent that can modify and improve *every* part of this stack, not just the model weights. Instead of humans bottlenecking development by manually engineering each component, the agent explores modifications across all layers—rewriting preprocessing scripts, adjusting prompts, refactoring training loops, optimizing inference code, restructuring architectures. The goal is to convert the entire AI system into something that scales with compute: just as we improve model performance by adding training compute, we should improve the entire system by giving an optimizer agent more resources to explore configurations. Full-stack optimization transforms AI development from human-bottlenecked iteration to compute-scalable optimization.